{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13d27c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from langdetect import detect\n",
    "from html import unescape\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ffae9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  class\n",
      "0      Get two nice notebooks and write it down for e...      0\n",
      "1                I<U+0092>m sobbing reading this thread!      1\n",
      "2                               Hope you have a nice day      0\n",
      "3      My wife came in when I was around half way thr...      1\n",
      "4            I am crying a lot of happy tears right now.      1\n",
      "...                                                  ...    ...\n",
      "12855            That's wild and a hell of a close call.      1\n",
      "12856              That's pretty much what my wife said.      0\n",
      "12857  I got into her line because she'd started work...      1\n",
      "12858         We've been friends for about a year or so.      1\n",
      "12859  As for how we got together, I was taking care ...      1\n",
      "\n",
      "[12485 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "base_path = \"C:/Users/ASUS/Desktop/Automatic-Privacy-Detection/data/\"\n",
    "\n",
    "training_dataset = base_path+'twitter-cikm-2010/labeled_training_set.csv'\n",
    "test_dataset = base_path+'twitter-cikm-2010/labeled_test_set.csv'\n",
    "\n",
    "\n",
    "def clean_tweets(df, min_length=8):\n",
    "    # Define regex patterns for matching\n",
    "    rt_pattern = r\"^RT @\\S+: \"\n",
    "    link_pattern = r\"http\\S+\"\n",
    "    mention_pattern = r\"@\\S+\"\n",
    "    hashtag_pattern = r\"#\\S+\"\n",
    "    unicode_pattern = r\"\\u0092\"\n",
    "\n",
    "    # Define function for removing regex patterns from text\n",
    "    def remove_patterns(text, patterns):\n",
    "        for pattern in patterns:\n",
    "            text = re.sub(pattern, \"\", text)\n",
    "        return text.replace('\\u0092', \"'\")\n",
    "\n",
    "    # Define function for checking if text is in English\n",
    "    def is_english(text):\n",
    "        try:\n",
    "            lang = detect(text)\n",
    "            return lang == \"en\"\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    # Remove unwanted patterns from text\n",
    "    df['text'] = df['text'].apply(lambda x: remove_patterns(x, [rt_pattern, link_pattern, mention_pattern, hashtag_pattern, unicode_pattern]))\n",
    "\n",
    "    # Remove non-English text and short text\n",
    "    df = df[df['text'].apply(lambda x: is_english(x) and len(x) >= min_length)]\n",
    "\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "\n",
    "# read in the CSV file\n",
    "df = pd.read_csv(training_dataset)\n",
    "\n",
    "# create a new column based on the values of the other columns\n",
    "df['class'] = df.apply(lambda x: 0 if x['Emotional_disclosure'] == 0 and x['Information_disclosure'] == 0 and x['Info_support'] == 0 and x['Emo_support'] == 0 else 1, axis=1)\n",
    "\n",
    "# rename the \"full_text\" column to \"text\"\n",
    "df = df.rename(columns={'full_text': 'text'})\n",
    "\n",
    "# drop all other columns except for \"text\" and \"class\"\n",
    "df = df[['text', 'class']]\n",
    "df = clean_tweets(df)\n",
    "df.to_csv(base_path+'training_set.csv', index=False)\n",
    "# print the resulting dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "479fb7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-sensitive:\n",
      "                                                     text  class\n",
      "0      Get two nice notebooks and write it down for e...      0\n",
      "2                               Hope you have a nice day      0\n",
      "21     I don<U+0092>t think he<U+0092>s seen my message.      0\n",
      "24     It<U+0092>s not uncommon for someone (especial...      0\n",
      "26     It takes longer but it is much safer and well ...      0\n",
      "...                                                  ...    ...\n",
      "12843                                    OP is a girl...      0\n",
      "12844                         He'll find out eventually.      0\n",
      "12847                     I don't understand your title.      0\n",
      "12848                               Insulting me now eh?      0\n",
      "12856              That's pretty much what my wife said.      0\n",
      "\n",
      "[4625 rows x 2 columns]\n",
      "\n",
      "Sensitive:\n",
      "                                                     text  class\n",
      "1                I<U+0092>m sobbing reading this thread!      1\n",
      "3      My wife came in when I was around half way thr...      1\n",
      "4            I am crying a lot of happy tears right now.      1\n",
      "5      Some asshole is cutting onions around me right...      1\n",
      "6      He<U+0092>s my father in every sense of the wo...      1\n",
      "...                                                  ...    ...\n",
      "12854             Let the cops help them, crooks or not.      1\n",
      "12855            That's wild and a hell of a close call.      1\n",
      "12857  I got into her line because she'd started work...      1\n",
      "12858         We've been friends for about a year or so.      1\n",
      "12859  As for how we got together, I was taking care ...      1\n",
      "\n",
      "[7860 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group the dataframe by the 'class' column\n",
    "grouped = df.groupby('class')\n",
    "\n",
    "# Get the group with class = 0\n",
    "class_0 = grouped.get_group(0)\n",
    "\n",
    "# Get the group with class = 1\n",
    "class_1 = grouped.get_group(1)\n",
    "\n",
    "# Print the two resulting dataframes\n",
    "print(\"Non-sensitive:\\n\", class_0)\n",
    "print(\"\\nSensitive:\\n\", class_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64ec8c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  class\n",
      "0     As time goes on, it's easier to recognize what...      0\n",
      "1     it's a lot to handle, you don't have to take i...      1\n",
      "2     If you got issues with your apartment, talk to...      0\n",
      "3     Check to see if your son's school has any open...      0\n",
      "4     Maybe you should try to take an outside perspe...      1\n",
      "...                                                 ...    ...\n",
      "4995  Stand up if someone disrespects you, let them ...      1\n",
      "4996  I think you should just continue what you are ...      1\n",
      "4997  Get a babysitter, take her to a quiet place an...      1\n",
      "4998  Try to sort out your feelings and talk to her ...      1\n",
      "4999  Speaking to a grief councillor is also somethi...      1\n",
      "\n",
      "[4867 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# read in the CSV file\n",
    "df = pd.read_csv(test_dataset)\n",
    "\n",
    "# create a new column based on the values of the other columns\n",
    "df['class'] = df.apply(lambda x: 0 if x['Emotional_disclosure'] == 0 and x['Information_disclosure'] == 0 and x['Info_support'] == 0 and x['Emo_support'] == 0 else 1, axis=1)\n",
    "\n",
    "# rename the \"full_text\" column to \"text\"\n",
    "df = df.rename(columns={'full_text': 'text'})\n",
    "\n",
    "# drop all other columns except for \"text\" and \"class\"\n",
    "df = df[['text', 'class']]\n",
    "df = clean_tweets(df)\n",
    "df.to_csv(base_path+'test_set.csv', index=False)\n",
    "# print the resulting dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d9fc904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-sensitive:\n",
      "                                                    text  class\n",
      "0     As time goes on, it's easier to recognize what...      0\n",
      "2     If you got issues with your apartment, talk to...      0\n",
      "3     Check to see if your son's school has any open...      0\n",
      "5     I say tell everyone, for better or worse you w...      0\n",
      "7     Maybe if you can see it as the enemy it is and...      0\n",
      "...                                                 ...    ...\n",
      "4374  The right person at the wrong time is still th...      0\n",
      "4446  We're open about them, because we accept that ...      0\n",
      "4525  So I need to have a solid \"base\" or I risk fee...      0\n",
      "4736  It<U+0092>s kind of like in the previous gener...      0\n",
      "4809  You put yourself out there and try to be a goo...      0\n",
      "\n",
      "[462 rows x 2 columns]\n",
      "\n",
      "Sensitive:\n",
      "                                                    text  class\n",
      "1     it's a lot to handle, you don't have to take i...      1\n",
      "4     Maybe you should try to take an outside perspe...      1\n",
      "6     It<U+0092>s  the best way to make him understa...      1\n",
      "8     It's good that you spoke your mind to your fat...      1\n",
      "10    You have places to go, people to see, and one ...      1\n",
      "...                                                 ...    ...\n",
      "4995  Stand up if someone disrespects you, let them ...      1\n",
      "4996  I think you should just continue what you are ...      1\n",
      "4997  Get a babysitter, take her to a quiet place an...      1\n",
      "4998  Try to sort out your feelings and talk to her ...      1\n",
      "4999  Speaking to a grief councillor is also somethi...      1\n",
      "\n",
      "[4405 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group the dataframe by the 'class' column\n",
    "grouped = df.groupby('class')\n",
    "\n",
    "# Get the group with class = 0\n",
    "class_0 = grouped.get_group(0)\n",
    "\n",
    "# Get the group with class = 1\n",
    "class_1 = grouped.get_group(1)\n",
    "\n",
    "# Print the two resulting dataframes\n",
    "print(\"Non-sensitive:\\n\", class_0)\n",
    "print(\"\\nSensitive:\\n\", class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae88836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
