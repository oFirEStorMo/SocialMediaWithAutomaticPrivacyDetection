{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb353217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from langdetect import detect\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99306365",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_path = \"C:/Users/ASUS/Desktop/Automatic-Privacy-Detection/data/\"\n",
    "\n",
    "def get_whisper(filename):\n",
    "    serial = []\n",
    "    text = []\n",
    "    for line in open(filename, 'r'):\n",
    "        new_data = json.loads(line)\n",
    "        serial.append(new_data[\"serial\"])\n",
    "        text.append(new_data[\"text\"])\n",
    "    return pd.DataFrame({\"serial\": serial, \"text\": text})\n",
    "\n",
    "def get_twitter(filename):\n",
    "    text = []\n",
    "    for line in open(filename, 'r'):\n",
    "        splitted = line.split('\\t')\n",
    "        if len(splitted) == 4:\n",
    "            text.append(splitted[2])\n",
    "    return pd.DataFrame({\"text\": text})\n",
    "\n",
    "def is_english(text):\n",
    "    try:\n",
    "        dl = detect(text)\n",
    "    except:\n",
    "#         print(text)\n",
    "        return False\n",
    "    return dl == 'en'\n",
    "\n",
    "def replace_if_lang(df, text):\n",
    "    def func(row):\n",
    "        if is_english(row[\"text\"]):\n",
    "            return row[\"text\"]\n",
    "        return \"\"\n",
    "    df['text'] = df.apply(func, axis=1).tolist()\n",
    "    return df\n",
    "\n",
    "def replace_in_df(df, regex, text):\n",
    "    def func(row):\n",
    "        return re.sub(regex, text, row[\"text\"])\n",
    "    df['text'] = df.apply(func, axis=1).tolist()\n",
    "    return df\n",
    "\n",
    "def clean_tweets(df, min_length=8):\n",
    "    # delete the entire tweet (1/2)\n",
    "    df = replace_in_df(df, r\".*RT @.*\", \"\") # retweets\n",
    "    df = replace_in_df(df, r\".*\\[\\[.*\", \"\") # placeholders\n",
    "    # delete only a part of the tweet\n",
    "    df = replace_in_df(df, r\"http(s?)://\\S+\", \"\") # links\n",
    "    df = replace_in_df(df, r\"@\\S+\", \"\") # mentions\n",
    "    df = replace_in_df(df, r\"#\\S+\", \"\") # hashtags\n",
    "    df = replace_in_df(df, r\"\\n\", \" \") # newline\n",
    "    df = replace_in_df(df, r\"  +\", \" \") # multiple spaces\n",
    "    df = replace_in_df(df, r\"^ \", \"\") # space at the begin of line\n",
    "    df = replace_in_df(df, r\" $\", \"\") # space at the end of line\n",
    "    # delete the entire tweet (2/2)\n",
    "    df = replace_if_lang(df, \"\") # texts not in English\n",
    "    df = df[df['text'].map(len) >= min_length] # short text\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "def get_datasets(whisper_filename, twitter_filename):\n",
    "    def get_dataset(filename, func, cls):\n",
    "        data = func(filename)\n",
    "        data[\"class\"] = cls\n",
    "        data = data[['text', 'class']]\n",
    "        return clean_tweets(data)\n",
    "    data_w = get_dataset(whisper_filename, get_whisper, \"sens\")\n",
    "#     data_t = get_dataset(twitter_filename, get_twitter, \"ns\")\n",
    "    return data_w\n",
    "\n",
    "def save_samples_data(num_samples, df_sens, df_ns, num_sens, num_ns, filename_prefix):\n",
    "    for count in range(num_samples):\n",
    "        df_sens[(num_sens*count):(num_sens*(count+1))].append(df_ns[(num_ns*count):(num_ns*(count+1))]).sample(frac=1, random_state=2**count).reset_index(drop=True).to_csv(filename_prefix+(\"0\"+str(count+1))[-2:]+\".csv\", index=False)\n",
    "    return\n",
    "\n",
    "df_sens = get_datasets(base_path+'whisper/final-anonymized.jun14.jun16.whisper-part-000.json', \n",
    "                base_path+'twitter-cikm-2010/labeled_training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f269296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820a2c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0910959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b874d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
